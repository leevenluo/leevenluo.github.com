<!--html4-->
<!--<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">-->

<!--html5-->
<!DOCTYPE html>
<html>
    <head>
        <meta http-equiv="Content-type" content="text/html; charset=utf-8">

        
            <meta name="description" content="" />
        

        <title>Leeven Luo - Spark环境搭建与实战</title>
        <link rel="stylesheet" href="/dist/css/bootstrap.min.css" type="text/css" media="screen" charset="utf-8"/>
        <link rel="stylesheet" href="/stylesheets/master.css" type="text/css" media="screen" charset="utf-8"/>

        <!--language highlight-->
        <link rel="stylesheet" href="/stylesheets/highlight.css" type="text/css" media="all" charset="utf-8"/>
        <link rel='alternate' type='application/rss+xml' href='http://feeds.feedburner.com/JoinTheConversation'/>
    </head>

    <body>
        <header id="header">
            <hgroup>
                <h1>leevenluo</h1>
                <h2>-- Don't put off till tomorrow what shoude be done today</h2>
            </hgroup>
        </header>

        <div id="header-hold">
            <nav id="header-nav">
                <ul id="main-nav">
                    <li><a href='/'><span>Home</span></a></li>
                    <li><a href='/categories.html'><span>Categories</span></a></li>
                    <li><a href='/about.html'><span>About</span></a></li>
                    <li><a href='http://github.com/leevenluo/' target='_blank' rel='me'><span>GitHub</span></a></li>
                </ul>

                <!-- remain search input
                <div id="main-search" class="input-group">
                    <input type="text" id="main-search-input" class="form-control">
                </div>
                -->
            </nav>
        </div>

        <div id='content'>
            <div class='home_box' id='home_left'>
                <div id='wrapper'>
    <div class='post'>
        <!-- page view counter id setting -->
        <script type="text/javascript"> window.unqid = "ed0e2884c90b1f850ca65438928c5a4f" </script>

        <div id="article-title">
            <h1><a href='/spark/scala/%E6%97%A5%E5%BF%97%E7%BB%9F%E8%AE%A1/2015/10/19/spark_and_scala_mac_step_by_step.html'>Spark环境搭建与实战</a></h1>
            <div class='date'> - 19 Oct 2015</div>
        </div>

        <div id="transpost">
            <p><a href=""><<<转载请注明出处,谢谢～>>></转载请注明出处,谢谢～></a></p>
        </div>

        <div class='body'>
            <h1>背景初识</h1>
<p>最近工作开始涉及离线大数据统计，鉴于Spark流行热度以及对项目适合的使用场景，决定基于Spark平台实现统计需求，同时借机接触、学习Spark。</p>
<p><b>Spark官网项目地址:</b> <a href="http://spark.apache.org/">点击这里</a></p>
<p><b>什么是Spark？</b></p>
<p><strong>Official: Apache Spark is a fast and general engine for large-scale data processing.</strong></p>
<h1>Scala + Spark 环境搭建</h1>
<h2>Scala环境搭建</h2>
<p><strong>1）</strong> <a href="http://www.scala-lang.org/download/">Scala下载</a> ，官网会根据系统选择对应的安装包</p>
<p><strong>2）</strong> 根据安装提示完成安装，配置 <a href="http://www.scala-lang.org/download/install.html">环境变量</a> ，本人配置如下：(zsh)</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c"># Add environment variable scala</span>
<span class="nb">export </span><span class="nv">SCALA_HOME</span><span class="o">=</span>/usr/local/opt/scala
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SCALA_HOME</span>/bin</code></pre></div><p>PS：配置完生效记得：$source ~/.zshrc</p>
<p><strong>3）</strong> 验证scala安装效果，参考 <a href="http://scala-lang.org/documentation/getting-started.html?_ga=1.164851575.990549473.1445225664#your_first_lines_of_code">这里</a></p>
<h2>Spark环境搭建</h2>
<p>Spark是基于分布式文件系统的计算平台，架构上都是集群部署，可是对于刚入门或者资源有限(单PC)未免门槛太高，有没有解决办法呢？</p>
<p>答案是肯定的，这里简单描述下Spark部署的几种机制：</p>
<p><strong>1）</strong> local模式，本地模式，本地单机模拟分布式集群，适用本地开发、测试</p>
<p><strong>2）</strong> standalone，集群模式，Master／Slave架构，有单点问题，需借助HA的框架解决</p>
<p><strong>3）</strong> on yarn，集群模式， 运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算</p>
<p><strong>4）</strong> on mesos，集群模式，运行在 mesos 资源管理器框架之上，由 mesos 负责资源管理，Spark 负责任务调度和计算</p>
<p><strong>5）</strong> on cloud，集群模式，比如 <span class="caps">AWS</span> 的 EC2，使用这个模式能很方便的访问 Amazon的 S3;Spark 支持多种分布式存储系统：HDFS 和 S3</p>
<p>这里先抛出两个问题，这也是笔者使用的时候思考过的，不是什么复杂的问题，不过有助于读者熟悉搭建流程细节，答案见文章结束Review：</p>
<p><strong>1）</strong> local模式存在Master／Slave模式吗？</p>
<p><strong>2）</strong> local模式和standalone模式区别是什么？</p>
<p>笔者搭建过程用的是local模式，重点也只讲local模式：</p>
<p><strong>1）</strong> <a href="http://spark.apache.org/downloads.html">Spark下载</a> ，注意下载选项Choose a package type，选择Pre-build Hadoop 1.X</p>
<p><strong>2）</strong> 完成第一步下载，解压tgz，将解压结果spark-1.5.1-bin-hadoop1 cp至/Users/leeven/Library/ ，同时配置环境变量：</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh"><span class="c"># Add environment variable spark</span>
<span class="nb">export </span><span class="nv">SPARK_HOME</span><span class="o">=</span>/Users/leeven/Library/spark-1.5.1-bin-hadoop1
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SPARK_HOME</span>/bin</code></pre></div><p>PS：配置完生效记得：$source ~/.zshrc</p>
<p><strong>3）</strong> 验证安装结果，如下图尝试运行spark-shell，测试例子参考 <a href="http://spark.apache.org/examples.html">这里</a></p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">leeven@luoxindeMacBook-Pro ~&gt; <span class="nv">$ </span>spark-shell
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _<span class="se">\ \/</span> _ <span class="se">\/</span> _ <span class="sb">`</span>/ __/  <span class="s1">&#39;_/</span>
<span class="s1">   /___/ .__/\_,_/_/ /_/\_\   version 1.5.1</span>
<span class="s1">      /_/</span>

<span class="s1">Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_60)</span>
<span class="s1">Type in expressions to have them evaluated.</span>
<span class="s1">Type :help for more information.</span>
<span class="s1">15/10/19 14:24:18 WARN SparkConf:</span>
<span class="s1">SPARK_WORKER_INSTANCES was detected (set to &#39;</span>2<span class="err">&#39;</span><span class="o">)</span>.
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --num-executors to specify the number of executors
 - Or <span class="nb">set </span>SPARK_EXECUTOR_INSTANCES
 - spark.executor.instances to configure the number of instances in the spark config.</code></pre></div><h2>eclipse+scala+spark 环境搭建</h2>
<p>在完成scala和spark环境搭建后，已经能在spark-shell中使用scala调用spark rdd API操作，进行简单测试和验证。现在已经可以开始开发spark程序：</p>
<p><strong>1）</strong> 开发scala程序</p>
<p><strong>2）</strong> 运用 <a href="https://github.com/CSUG/real_world_scala/blob/master/02_sbt.markdown">sbt</a> 打包jar包</p>
<p><strong>3）</strong> 使用spark-submit命令提交jar包执行job</p>
<p>笔者在参考sbt使用流程觉得比较繁琐，通过查阅网上资料，可以基于eclipse搭建集scala开发、打包IDE，这样的话应该能节约开发成本，scala官网有一个scala-IDE也是基于eclipse平台，不过笔者之前就已经有一个eclipse版本，也不想重新再装一个，正好scala可以当插件下载，搭建流程如下：</p>
<p><strong>1）</strong> eclipse Help &#8594; Install New Software&#8230; Add http://download.scala-ide.org/sdk/lithium/e44/scala211/stable/site</p>
<p><strong>2）</strong> 选择Scala <span class="caps">IDE</span> For Eclipse &amp;&amp; Scala <span class="caps">IDE</span> For Eclipse development support，安装即可</p>
<p><strong>3）</strong> 建立Scala工程，在工程Build Path &#8594; Libraries添加spark lib依赖，依赖jar包：/Users/leeven/Library/spark-1.5.1-bin-hadoop1/lib/spark-assembly-1.5.1-hadoop1.2.1.jar ，假如出现不兼容问题，推荐将scala版本切换至scala 2.10.*版本，配置截图如下：</p>
<p><img width="811px" height="499px" src="/images/sparkBegin/eclipse_config_build_path.png" /></p>
<h2>Spark应用实战</h2>
<p>接下来基于以上搭建的Spark环境，运用eclipse＋scala＋sparklib的IDE，实现一个统计词频的Spark Job：</p>
<p><strong>1）</strong> eclipse建立Scala工程，建立Scala Object，编写Scala统计词频程序，如下：</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>

<span class="k">object</span> <span class="nc">MyProgram</span> <span class="o">{</span>
  
<span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]){</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">args</span><span class="o">.</span><span class="n">length</span> <span class="o">!=</span> <span class="mi">1</span> <span class="o">){</span>
      <span class="n">println</span><span class="o">(</span><span class="s">&quot;usage is org.test.WordCount &lt;input&gt;&quot;</span><span class="o">)</span>
      <span class="k">return</span>
    <span class="o">}</span>
    
    <span class="c1">//初始化SparkContext</span>
    <span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">()</span>

    <span class="c1">//读待统计文件</span>
    <span class="k">val</span> <span class="n">textFile</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="n">args</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>

    <span class="c1">//迭代按行分割词，并放入tuple，将最终tuple reduceByKey，累加出现的次数</span>
    <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">textFile</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;\\s+&quot;</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="n">word</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="mi">1</span><span class="o">)).</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)</span>
                   
    <span class="c1">//打印统计结果</span>
    <span class="n">result</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">a</span> <span class="k">=&gt;</span> <span class="n">print</span><span class="o">(</span><span class="n">a</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">))</span>
    <span class="n">println</span><span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="n">count</span><span class="o">)</span>
    
    <span class="c1">//先将worker结果汇总到master并打印统计结果</span>
    <span class="k">var</span> <span class="n">resultCollect</span> <span class="k">=</span> <span class="n">result</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
    <span class="n">resultCollect</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">a</span> <span class="k">=&gt;</span> <span class="n">print</span><span class="o">(</span><span class="n">a</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">))</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></div><p><strong>2）</strong> 将scala工程export成jar包，比如myprogram.jar，然后在执行目录存放带统计文件(测试的是spark目录下README.md)，先用jps命令查询spark启用master和worker的情况，假如没有启用，则先调用start-all.sh脚本启用spark，再用spark-submit提交Job任务：</p>
<div class="highlight"><pre><code class="language-sh" data-lang="sh">leeven@luoxindeMacBook-Pro ~/Desktop/spark/TotalCount&gt; <span class="nv">$ </span>jps
<span class="m">2112</span> Jps
1371

leeven@luoxindeMacBook-Pro ~/Desktop/spark/TotalCount&gt; <span class="nv">$ </span>~/Library/spark-1.5.1-bin-hadoop1/sbin/start-all.sh
starting org.apache.spark.deploy.master.Master, logging to /Users/leeven/Library/spark-1.5.1-bin-hadoop1/sbin/../logs/spark-leeven-org.apache.spark.deploy.master.Master-1-luoxindeMacBook-Pro.local.out
localhost: starting org.apache.spark.deploy.worker.Worker, logging to /Users/leeven/Library/spark-1.5.1-bin-hadoop1/sbin/../logs/spark-leeven-org.apache.spark.deploy.worker.Worker-1-luoxindeMacBook-Pro.local.out
localhost: starting org.apache.spark.deploy.worker.Worker, logging to /Users/leeven/Library/spark-1.5.1-bin-hadoop1/sbin/../logs/spark-leeven-org.apache.spark.deploy.worker.Worker-2-luoxindeMacBook-Pro.local.out

leeven@luoxindeMacBook-Pro ~/Desktop/spark/TotalCount&gt; <span class="nv">$ </span>jps
<span class="m">2386</span> Worker
<span class="m">2435</span> Jps
<span class="m">2213</span> Master
1371
<span class="m">2334</span> Worker

leeven@luoxindeMacBook-Pro ~/Desktop/spark/TotalCount&gt; <span class="nv">$ </span>spark-submit --name <span class="s2">&quot;MyProgram&quot;</span> --master spark://localhost:7077 --executor-memory 512M --class MyProgram ./myprogram.jar ./README.md
15/10/19 20:25:46 WARN SparkConf:
SPARK_WORKER_INSTANCES was detected <span class="o">(</span><span class="nb">set </span>to <span class="s1">&#39;2&#39;</span><span class="o">)</span>.
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --num-executors to specify the number of executors
 - Or <span class="nb">set </span>SPARK_EXECUTOR_INSTANCES
 - spark.executor.instances to configure the number of instances in the spark config.

15/10/19 20:25:47 WARN MetricsSystem: Using default name DAGScheduler <span class="k">for</span> <span class="nb">source </span>because spark.app.id is not set.
15/10/19 20:25:50 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="k">for</span> your platform... using <span class="nb">builtin</span>-java classes where applicable
15/10/19 20:25:50 WARN LoadSnappy: Snappy native library not loaded
268
<span class="o">(</span>package,1<span class="o">)</span>
<span class="o">(</span>this,1<span class="o">)</span>
...
<span class="o">(</span>结果省略<span class="o">)</span></code></pre></div><p>spark同时还提供WebUI供跑任务流程查询，包括master和slave，消耗的内存、耗时等，默认的URL：http://localhost:8080/ ，效果如下图：</p>
<p><img width="811px" height="499px" src="/images/sparkBegin/spark_webui.png" /></p>
<h1>过程Review</h1>
<p>到这里，Spark的搭建和基本应用已经走完一遍，其实回望整个搭建流程，还是比较简单的，没有太多环境的耦合，最终基于eclipse配置的IDE仅仅是一种快速开发Spark应用程序的方式，网上还有很多种IDE的搭建教程，有兴趣的读者可自行尝试。</p>
<p>之前开头遗留的问题在这里解答下，</p>
<p><strong>1）</strong> local模式存在Master／Slave模式吗？<br />
答：存在，最终执行提交Job看WebUI就清楚了</p>
<p><strong>2）</strong> local模式和standalone模式区别是什么？<br />
答：这个问题其实是在第一个问题基础之上回答的，两种模式都有Master和Slave，表面感觉没有区别，其实区别仅在对Hadoop环境的依赖，standalone需要依赖</p>
<p>整个流程读者是不是都清楚了？实战部分的代码是不是也看懂了，包括提交Job的执行日志？笔者抛出两个问题，读者能否解答：</p>
<p><strong>1）</strong> start-all.sh启动脚本为什么多启动了一个Slave？</p>
<p><strong>2）</strong> 实战程序执行结果打印日志是否能对应得上？</p>
        </div>

        <!--
        <div class='sns'>
        <div class="addthis_toolbox addthis_default_style ">
        <a class="addthis_button_preferred_1"></a>
        <a class="addthis_button_preferred_2"></a>
        <a class="addthis_button_preferred_3"></a>
        <a class="addthis_button_preferred_6"></a>
        <a class="addthis_button_preferred_7"></a>
        <a class="addthis_button_compact"></a>
        </div>
        <script type="text/javascript">var addthis_config = {"data_track_clickback":true};</script>
        <script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid=ra-4df3c7a42c2a2e7e"></script>
        </div>
        -->
        <br>

        <div class="related">
            <h3>Related Posts</h3>
            <table class="post-list">
                
                <tr>
                    <th><a href='/algorithm/2015/05/26/HDOJ_1042.html'>HDOJ-1042</a></th>
                    <td>26 May 2015</td>
                    <td><a href='/algorithm/2015/05/26/HDOJ_1042.html#disqus_thread'>Comments</a></td>
                </tr>
                
                <tr>
                    <th><a href='/algorithm/2015/05/20/HDOJ_1002.html'>HDOJ-1002</a></th>
                    <td>20 May 2015</td>
                    <td><a href='/algorithm/2015/05/20/HDOJ_1002.html#disqus_thread'>Comments</a></td>
                </tr>
                
                <tr>
                    <th><a href='/scrapy/python/crawler/2015/02/04/scrapyAdvancedSkilled.html'>Scrapy实战进阶技巧</a></th>
                    <td>04 Feb 2015</td>
                    <td><a href='/scrapy/python/crawler/2015/02/04/scrapyAdvancedSkilled.html#disqus_thread'>Comments</a></td>
                </tr>
                
            </table>
        </div>

        <div id="disqus_thread"></div>
    </div>
</div>

            </div>

            <div class='home_box' id='home_right'>
            <h2 id='total_page_view'>TotalPageView</h2>

            <h2>Categories</h2>
            <div id='github-projects-categ'>
                <div class="repo">
                    <h4><a href="/categories.html">博客讨论 ( 5 )</a></h4>
                    <h4><a href="/categories.html">域名讨论 ( 1 )</a></h4>
                    <h4><a href="/categories.html">Mac系统讨论 ( 1 )</a></h4>
                    <h4><a href="/categories.html">Python ( 3 )</a></h4>
                    <h4><a href="/categories.html">爬虫讨论 ( 3 )</a></h4>
                </div>
            </div>

            <h2>Open Source Proj</h2>
            <div id='open-source-proj-index'>
                <div class="repo">
                    <h4><a href="/categories.html">Scrapy ( 3 )</a></h4>
                </div>
            </div>

            <h2>Popular Posts</h2>
            <div id='github-projects-pop'>
                <div class="repo">
                    
                        <h3><a href="/spark/scala/%E6%97%A5%E5%BF%97%E7%BB%9F%E8%AE%A1/2015/10/19/spark_and_scala_mac_step_by_step.html">Spark环境搭建与实战</a></h3>
                    
                        <h3><a href="/algorithm/2015/05/26/HDOJ_1042.html">HDOJ-1042</a></h3>
                    
                        <h3><a href="/algorithm/2015/05/20/HDOJ_1002.html">HDOJ-1002</a></h3>
                    
                        <h3><a href="/scrapy/python/crawler/2015/02/04/scrapyAdvancedSkilled.html">Scrapy实战进阶技巧</a></h3>
                    
                        <h3><a href="/scrapy/python/crawler/2015/01/30/scrapyBeginning.html">Scrapy使用小结</a></h3>
                    
                        <h3><a href="/scrapy/python/crawler/2015/01/28/scrapyInstallConfig.html">Scrapy安装配置初探</a></h3>
                    
                        <h3><a href="/mac/windows7/2015/01/25/imacInstallWin7.html">imac安装win7双系统小记</a></h3>
                    
                        <h3><a href="/domain/blog/2015/01/22/buildBlog_CustomDomain.html">域名申请与配置小结</a></h3>
                    
                        <h3><a href="/blog/2013/04/03/buildBlog_hacking.html">一起写blog-Hacking篇</a></h3>
                    
                        <h3><a href="/blog/2013/03/30/buildBlog_building.html">一起写blog-搭建篇</a></h3>
                    
                        <h3><a href="/blog/2013/03/28/buildBlog_configure.html">一起写blog-配置篇</a></h3>
                    
                        <h3><a href="/blog/2013/03/28/buildBlog_beginning.html">一起写blog-起始篇</a></h3>
                    
                </div>
            </div>

            <div id="article-index">
                <div id="article-index-fixed">
                    <h2>Catalog</h2>
                    <div id='toc' class='repo'>
                    </div>
                </div>
            </div>

            </div>
            <div class='clearfix'></div>
        </div>

        <div id='footer'>
            Copyright &copy; 2015 Leeven Luo. Theme and code by
            <a href="http://github.com/leevenluo">Leevenluo</a>. Hosted by
            <a href='http://github.com/leevenluo/leevenluo.github.com/' target='_blank'>GitHub</a> and powered by
            <a href='http://github.com/mojombo/jekyll'>Jekyll</a>.
        </div>

        <script type="text/javascript" src="/dist/js/jquery.min.js" charset="utf-8" scriptid="jqueryId"></script>
        <script type="text/javascript" src="/dist/js/bootstrap.min.js" charset="utf-8" scriptid="bootstpId"></script>
        <script type="text/javascript" src="/dist/js/toc.js" charset="utf-8" scriptid="tocId"></script>
        <script type="text/javascript" src="/javascripts/main.js" charset="utf-8" scriptid="mainId"></script>

        <!-- page view counter loading -->
        <script type="text/javascript" charset="utf-8">
            var div     = '<div id="pageView">';
            var wording = '<p>PageView : </p>';
            var src     = div + wording + '<script src="http://counter1.allfreecounter.com/private/counter.js?c=';
            document.write(src + window.unqid + '" charset="utf-8"><\/script></div>');

            var jsSrc   = '//ra.revolvermaps.com/0/0/6.js?i=0nmhf2tutle&amp;m=0&amp;s=220&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=0'
            div         = '<div id="totalPageView">';
            src         = div + '<script type="text/javascript" src="' + jsSrc;
            document.write(src + '" ><\/script></div>');
        </script>
        <script type="text/javascript" src="/javascripts/pageview.js" charset="utf-8" scriptid="pvId"></script>
    </body>

</html>







